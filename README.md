## Make VLMs Memorize Normality: Memory-Enhanced Vision-Language Model for Video Anomaly Detection ğŸ‘‹
![MEMVLM](https://github.com/user-attachments/assets/830f86d5-5622-4547-8c54-543fa40b7dd4)

# MEMVLM

This is the **official code repository** for **Make VLMs Memorize Normality: Memory-Enhanced Vision-Language Model for Video Anomaly Detection(MEMVLM)**.

## ğŸ” Introduction

MEMVLM is a vision-language model designed for multimodal anomaly detection.

This repository currently provides evaluation code for measuring model performance.

## ğŸš€ Quick Start

Make sure all dependencies in eval.py are installed, then run the following command to evaluate the model:

```bash
python eval.py
```

## ğŸ“Œ Full Code

The full development code will be released after the paper is accepted.
